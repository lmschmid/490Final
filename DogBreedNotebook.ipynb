{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Identification: DLNN Final Project\n",
    "Ian Battin & Liam Schmid\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this project, we are tackling the Kaggle Competition: [Dog Breed Identification](https://www.kaggle.com/c/dog-breed-identification/).\n",
    "\n",
    "In this competition, you are given a dataset containing images of 120 different breeds of dogs. It is our job to classify images in the test set into these 120 different breeds.\n",
    "\n",
    "Being an image based challenge, CNNs are the obvious choice. We will discuss the different strategies and optimizations we tried as well as provide all the code used at each step.\n",
    "\n",
    "## Preparing the data\n",
    "The data is provided in two folders - train and test - where each file is an image. There is a labels.csv file which maps an image filename to a label (breed).\n",
    "\n",
    "To prepare our data for use, we needed to move all of the images in the training set into seperate folders grouped by breed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a labels file in the format provided by Kaggle and outputs a mapping of photo ids to their breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from keras import models\n",
    "from keras.preprocessing import image\n",
    "from keras import backend\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generateIDMapping(labelsFile):\n",
    "    idMap = {}\n",
    "\n",
    "    with open(labelsFile) as f:\n",
    "        for line in f:\n",
    "            if line.rstrip() != 0 and line.rstrip() != \"id,breed\":\n",
    "                id, breed = line.rstrip().split(\n",
    "                    ',')[0], line.rstrip().split(',')[1]\n",
    "\n",
    "                idMap[id] = breed\n",
    "\n",
    "    return idMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions create a train directory, validation directory, and test directory. For the train and validation directories, it generates subfolders for each image type to work with fit_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTrainDirectories(idMap, source, dest):\n",
    "    if os.path.exists(dest):\n",
    "        shutil.rmtree(dest)\n",
    "\n",
    "    for filename in os.listdir(source):\n",
    "        id = filename.split('.')[0]\n",
    "        breed = idMap[id]\n",
    "\n",
    "        srcPath = source+\"/\"+filename\n",
    "        destPath = dest+\"/\"+breed+\"/\"+filename\n",
    "\n",
    "        path = Path(dest+\"/\"+breed)\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copyfile(srcPath, destPath)\n",
    "\n",
    "\n",
    "def makeValidationDirectories():\n",
    "    for dirname in os.listdir('train'):\n",
    "        samples = np.asarray(os.listdir('train/'+dirname))\n",
    "        valSamples = np.random.choice(samples, len(samples)//4, replace=False)\n",
    "\n",
    "        if os.path.exists('validation/'+dirname):\n",
    "            shutil.rmtree('validation/'+dirname)\n",
    "        for sample in valSamples:\n",
    "            path = Path('validation/'+dirname)\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            shutil.move('train/'+dirname+'/'+sample,\n",
    "                        'validation/'+dirname+'/'+sample)\n",
    "\n",
    "\n",
    "def makeTestDirectory(source, dest):\n",
    "    if os.path.exists(dest):\n",
    "        shutil.rmtree(dest)\n",
    "\n",
    "    dest = dest + \"/images\"\n",
    "    path = Path(dest)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(source):\n",
    "        srcPath = source+\"/\"+filename\n",
    "        destPath = dest+\"/\"+filename\n",
    "        shutil.copyfile(srcPath, destPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idMap = generateIDMapping('data/labels.csv')\n",
    "\n",
    "makeTrainDirectories(idMap, 'data/train', 'train')\n",
    "makeValidationDirectories()\n",
    "makeTestDirectory('data/test', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at predictions\n",
    "Let's look at the top 5 predictions for example images.\n",
    "\n",
    "<img src=\"data/train/0ac12f840df2b15d46622e244501a88c.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the model\n",
    "Let's get a better sense of how inception is looking at the images. We will look at th channel outputs for several images.\n",
    "\n",
    "First, we'll get a tensor representation of our sample image.\n",
    "\n",
    "First, we get the activation model, or a model which returns the outputs of the included layers.\n",
    "<img src='data/train/a21caab32c00011d38f1e409fbf65d19.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tensor(img_path, display_img=False):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img_tensor = image.img_to_array(img)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "    img_tensor /= 255.\n",
    "\n",
    "    if display_img:\n",
    "        plt.imshow(img_tensor[0])\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "img_tensor = get_img_tensor('data/train/a21caab32c00011d38f1e409fbf65d19.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get the activation model, or a model which returns the outputs of the included layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('Model46.h5')\n",
    "\n",
    "inception = model.layers[0]\n",
    "\n",
    "# Returns model which returns output of first n_layers given an image.\n",
    "def get_activation_model(inception_model, n_layers=294):\n",
    "    layer_outputs = [\n",
    "        layer.output for layer in inception_model.layers[1:n_layers]]\n",
    "\n",
    "    activation_model = models.Model(\n",
    "        inputs=inception_model.layers[0].input, outputs=layer_outputs)\n",
    "\n",
    "    return activation_model\n",
    "\n",
    "activation_model = get_activation_model(inception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call predict from our activation model. This yields us the outputs from each layer for this image. We organize each channels output for a given layer in a grid and display it with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale output values to be between 0,255 to display\n",
    "def scale_img_values(channel_img):\n",
    "    channel_img -= channel_img.mean()\n",
    "    channel_img /= channel_img.std()\n",
    "    channel_img *= 64\n",
    "    channel_img += 128\n",
    "    channel_img = np.clip(channel_img, 0, 255).astype('uint8')\n",
    "\n",
    "    return channel_img\n",
    "\n",
    "def analyze_channels_for_img(inception, activation_model, img_tensor,\n",
    "                             n_layers=294, imgs_per_row=16, n_activations=16):\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "\n",
    "    first_layer_activation = activations[0]\n",
    "\n",
    "    layer_names = [layer.name for layer in inception.layers[1:n_layers]]\n",
    "\n",
    "    for layer_name, activation in zip(layer_names[:n_activations],\n",
    "                                      activations[:n_activations]):\n",
    "        if 'batch_normalization' in layer_name:\n",
    "            continue\n",
    "\n",
    "        # Channels in output\n",
    "        n_channels = activation.shape[-1]\n",
    "\n",
    "        img_size = activation.shape[1]\n",
    "        # Columns to display in grid\n",
    "        n_cols = n_channels // imgs_per_row\n",
    "\n",
    "        display_grid = np.zeros((img_size * n_cols, imgs_per_row * img_size))\n",
    "\n",
    "        for col in range(n_cols):\n",
    "            for row in range(imgs_per_row):\n",
    "                channel_img = scale_img_values(\n",
    "                    activation[0, :, :, col * imgs_per_row + row])\n",
    "\n",
    "                display_grid[col * img_size: (col + 1) * img_size,\n",
    "                             row * img_size: (row + 1) * img_size] = channel_img\n",
    "\n",
    "        scale = 1. / img_size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "analyze_channels_for_img(inception, activation_model, img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare for this new image.\n",
    "<img src='data/train/0ec9be8b32f2b9eff2b817a7f722b118.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = get_img_tensor('data/train/0ec9be8b32f2b9eff2b817a7f722b118.jpg')\n",
    "\n",
    "analyze_channels_for_img(inception, activation_model, img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
